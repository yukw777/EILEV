{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T-SNE Plot to Show the Distribution Shift From Ego4D to EPIC-KITCHENS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw a T-SNE plot for randomly selected videos from Ego4D and EPIC-KITCHENS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "ego4d_emb_files = glob.glob(\"../../eilev-blip2-opt-2.7b-vision-model-embs/ego4d/*.pt\")\n",
    "random.shuffle(ego4d_emb_files)\n",
    "ego4d_emb_files = ego4d_emb_files[:20000]\n",
    "print(\"Ego4D\")\n",
    "for file in ego4d_emb_files[:3]:\n",
    "    print(file)\n",
    "\n",
    "epic_kitchens_emb_files = glob.glob(\n",
    "    \"../../eilev-blip2-opt-2.7b-vision-model-embs/EPIC-KITCHENS/*.pt\"\n",
    ")\n",
    "random.shuffle(epic_kitchens_emb_files)\n",
    "epic_kitchens_emb_files = epic_kitchens_emb_files[:20000]\n",
    "print(\"EPIC-KITCHENS\")\n",
    "for file in epic_kitchens_emb_files[:3]:\n",
    "    print(file)\n",
    "\n",
    "vid_embs = torch.stack(\n",
    "    [torch.load(file) for file in ego4d_emb_files + epic_kitchens_emb_files]\n",
    ").numpy()\n",
    "print(f\"vid_embs.shape = {vid_embs.shape}\")\n",
    "# 0 = ego4d, 1 = epic-kitchens\n",
    "y = np.array([0] * len(ego4d_emb_files) + [1] * len(epic_kitchens_emb_files))\n",
    "assert vid_embs.shape[0] == y.shape[0]\n",
    "\n",
    "sample_df = pd.DataFrame()\n",
    "sample_df[\"y\"] = y\n",
    "sample_df[\"Dataset\"] = sample_df[\"y\"].apply(\n",
    "    lambda i: \"Ego4D\" if i == 0 else \"EPIC-KITCHENS\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "\n",
    "def tsne(vid_embs: np.ndarray) -> tuple[np.ndarray, np.ndarray]:\n",
    "    pca = PCA(n_components=50)\n",
    "    pca_result = pca.fit_transform(vid_embs)\n",
    "\n",
    "    tsne = TSNE()\n",
    "    tsne_results = tsne.fit_transform(pca_result)\n",
    "    return tsne_results[:, 0], tsne_results[:, 1]\n",
    "\n",
    "\n",
    "tsne_one, tsne_two = tsne(vid_embs)\n",
    "sample_df[\"tsne-one\"] = tsne_one\n",
    "sample_df[\"tsne-two\"] = tsne_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "plt.rcParams[\"font.family\"] = \"stixgeneral\"\n",
    "plt.figure(figsize=(16, 10))\n",
    "sns.scatterplot(\n",
    "    x=\"tsne-one\",\n",
    "    y=\"tsne-two\",\n",
    "    hue=\"Dataset\",\n",
    "    palette=sns.color_palette(\"hls\", 2),\n",
    "    data=sample_df,\n",
    "    legend=\"full\",\n",
    ")\n",
    "plt.xlabel(None)\n",
    "plt.ylabel(None)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure out which common actions from EPIC-KITCHENS are present in Ego4D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def count_actions(*files):\n",
    "    counter = Counter()\n",
    "    for file in files:\n",
    "        with open(file, newline=\"\") as f:\n",
    "            csvreader = csv.DictReader(f)\n",
    "            for item in csvreader:\n",
    "                if not item[\"structured_verb\"] or not item[\"structured_noun\"]:\n",
    "                    continue\n",
    "                counter[(item[\"structured_verb\"], item[\"structured_noun\"])] += 1\n",
    "    return counter\n",
    "\n",
    "\n",
    "ego4d_annotation_files = [\n",
    "    \"../../ego4d/fho_main_train_frames-448px-subsample-8/narrated_actions.csv\",\n",
    "    \"../../ego4d/fho_main_val_frames-448px-subsample-8/narrated_actions.csv\",\n",
    "    \"../../ego4d/fho_main_test_frames-448px-subsample-8/narrated_actions.csv\",\n",
    "]\n",
    "ego4d_action_counter = count_actions(*ego4d_annotation_files)\n",
    "\n",
    "epic_kitchens_annotation_files = [\n",
    "    \"../../EPIC-KITCHENS/train-epic-kitchens-subsample-8/narrated_actions.csv\",\n",
    "    \"../../EPIC-KITCHENS/val-epic-kitchens-subsample-8/narrated_actions.csv\",\n",
    "]\n",
    "epic_kitchens_action_counter = count_actions(*epic_kitchens_annotation_files)\n",
    "\n",
    "print(\"Ego4D\")\n",
    "for action in ego4d_action_counter.most_common(10):\n",
    "    print(action)\n",
    "print(\"EPIC-KITCHENS\")\n",
    "for action in epic_kitchens_action_counter.most_common(10):\n",
    "    print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"('turn_on_(switch_on,_start,_light)', 'faucet_(faucet,_tap)'): \"\n",
    "    + str(\n",
    "        ego4d_action_counter[\n",
    "            (\"turn_on_(switch_on,_start,_light)\", \"faucet_(faucet,_tap)\")\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"('turn_off_(turn_off,_switch_off)', 'faucet_(faucet,_tap)'): \"\n",
    "    + str(\n",
    "        ego4d_action_counter[\n",
    "            (\"turn_off_(turn_off,_switch_off)\", \"faucet_(faucet,_tap)\")\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"('open', 'cabinet_(cabinet,_compartment,_cupboard)'): \"\n",
    "    + str(ego4d_action_counter[(\"open\", \"cabinet_(cabinet,_compartment,_cupboard)\")])\n",
    ")\n",
    "print(\"('open', 'drawer'): \" + str(ego4d_action_counter[(\"open\", \"drawer\")]))\n",
    "print(\n",
    "    \"('close', 'cabinet_(cabinet,_compartment,_cupboard)'): \"\n",
    "    + str(ego4d_action_counter[(\"close\", \"cabinet_(cabinet,_compartment,_cupboard)\")])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw a T-SNE plot for these actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def get_action_annotations_map(\n",
    "    annotation_files: list[str],\n",
    ") -> dict[tuple[str, str], list[dict]]:\n",
    "    action_annotations_map: dict[tuple[str, str], list[dict]] = defaultdict(list)\n",
    "    for file in annotation_files:\n",
    "        with open(file, newline=\"\") as f:\n",
    "            csvreader = csv.DictReader(f)\n",
    "            for item in csvreader:\n",
    "                if not item[\"structured_verb\"] or not item[\"structured_noun\"]:\n",
    "                    continue\n",
    "                action_annotations_map[\n",
    "                    (item[\"structured_verb\"], item[\"structured_noun\"])\n",
    "                ].append(item)\n",
    "\n",
    "    return action_annotations_map\n",
    "\n",
    "\n",
    "def read_embs(\n",
    "    action: tuple[str, str],\n",
    "    action_annotations_map: dict[tuple[str, str], list[dict]],\n",
    "    emb_dir: str,\n",
    ") -> np.ndarray:\n",
    "    vid_emb_list: list[torch.Tensor] = []\n",
    "    for item in action_annotations_map[action]:\n",
    "        vid_emb_list.append(torch.load(Path(emb_dir) / (item[\"frame_path\"] + \".pt\")))\n",
    "\n",
    "    return torch.stack(vid_emb_list).numpy()\n",
    "\n",
    "\n",
    "ego4d_actions = [\n",
    "    (\"turn_on_(switch_on,_start,_light)\", \"faucet_(faucet,_tap)\"),\n",
    "    (\"turn_off_(turn_off,_switch_off)\", \"faucet_(faucet,_tap)\"),\n",
    "    (\"open\", \"cabinet_(cabinet,_compartment,_cupboard)\"),\n",
    "]\n",
    "epic_kitchens_actions = [(\"turn-on\", \"tap\"), (\"turn-off\", \"tap\"), (\"open\", \"cupboard\")]\n",
    "\n",
    "ego4d_action_annotations_map = get_action_annotations_map(ego4d_annotation_files)\n",
    "epic_kitchens_action_annotations_map = get_action_annotations_map(\n",
    "    epic_kitchens_annotation_files\n",
    ")\n",
    "\n",
    "action_dfs: list[pd.DataFrame] = []\n",
    "\n",
    "for ego4d_action, epic_kitchens_action in zip(ego4d_actions, epic_kitchens_actions):\n",
    "    ego4d_embs = read_embs(\n",
    "        ego4d_action,\n",
    "        ego4d_action_annotations_map,\n",
    "        \"../../eilev-blip2-opt-2.7b-vision-model-embs/ego4d/\",\n",
    "    )\n",
    "    epic_kitchens_embs = read_embs(\n",
    "        epic_kitchens_action,\n",
    "        epic_kitchens_action_annotations_map,\n",
    "        \"../../eilev-blip2-opt-2.7b-vision-model-embs/EPIC-KITCHENS/\",\n",
    "    )\n",
    "    vid_embs = np.concatenate((ego4d_embs, epic_kitchens_embs), axis=0)\n",
    "    tsne_one, tsne_two = tsne(vid_embs)\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df[\"y\"] = np.array([0] * ego4d_embs.shape[0] + [1] * epic_kitchens_embs.shape[0])\n",
    "    df[\"Dataset\"] = df[\"y\"].apply(lambda i: \"Ego4D\" if i == 0 else \"EPIC-KITCHENS-100\")\n",
    "    df[\"tsne-one\"] = tsne_one\n",
    "    df[\"tsne-two\"] = tsne_two\n",
    "    action_dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"darkgrid\")\n",
    "plt.rcParams[\"font.family\"] = \"stixgeneral\"\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(16, 4))\n",
    "\n",
    "ax = axs[0]\n",
    "sns.scatterplot(\n",
    "    x=\"tsne-one\",\n",
    "    y=\"tsne-two\",\n",
    "    hue=\"Dataset\",\n",
    "    palette=sns.color_palette(\"hls\", 2),\n",
    "    data=sample_df,\n",
    "    ax=ax,\n",
    ")\n",
    "ax.set_xlabel(None)\n",
    "ax.set_ylabel(None)\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.set_title(\"Random 40K Subset\", fontsize=30, fontweight=\"bold\")\n",
    "ax.get_legend().remove()\n",
    "ax.collections[0].set_rasterized(True)\n",
    "ax.grid(False)\n",
    "\n",
    "for i, ((verb, noun), df) in enumerate(zip(epic_kitchens_actions, action_dfs)):\n",
    "    ax = axs[i + 1]\n",
    "    sns.scatterplot(\n",
    "        x=\"tsne-one\",\n",
    "        y=\"tsne-two\",\n",
    "        hue=\"Dataset\",\n",
    "        palette=sns.color_palette(\"hls\", 2),\n",
    "        data=df,\n",
    "        ax=ax,\n",
    "    )\n",
    "    ax.set_xlabel(None)\n",
    "    ax.set_ylabel(None)\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_title(\n",
    "        (\" \".join(verb.split(\"-\") + noun.split(\"-\"))).title(),\n",
    "        fontsize=30,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "    ax.get_legend().remove()\n",
    "    ax.collections[0].set_rasterized(True)\n",
    "    ax.grid(False)\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"tsne.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eilev-NpCwgrX9-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
